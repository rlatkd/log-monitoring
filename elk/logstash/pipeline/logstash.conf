#kafka를 이용하지않고 logback에서 logstash로 다이렉트로 쏠 떄
#5000번 포트로 들어온 데이터를 JSON 파싱
# input {
#   tcp {
#     port => 5000
#     codec => json_lines
#   }
# }

#kafka에서 메시지를 consume 해서 가져옴
input {
  kafka {
    bootstrap_servers => "kafka:29092" #같은 도커 네트워크에 있으므로 kafka:29092 사용
    topics => ["kafka-elk"] #kafka 토픽
    consumer_threads => 5 #consume 쓰레드 갯수
    partition_assignment_strategy => "round_robin" #라운드 로빈 방식으로 부하분산(로드밸런싱)
    decorate_events => true
  }
}

#elasticsearch에 보냄
output {
  elasticsearch {
    hosts => "elasticsearch:9200"
    user => "elastic"
    password => "elastic123!@#"

    #elasticsearch의 index는 RDBMS의 database와 같은 개념, 즉 데이터베이스이름
    index => "logs"
  }
}